{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeaDkONeNvSA"
   },
   "source": [
    "# PROYECTO FINAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivos:\n",
    "- Realizar la predicción de ORFs de la accesión NC_014976.1 del genoma completo de  'Bacillus subtilis'\n",
    "- Comparar los resultados obtenidos con las herramientas orf_finder y pyrodigal para la predicción de ORFs\n",
    "- Realizar la anotación del genoma con el servidor en línea prokka\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empleó el módulo de python, \"pyrodigal\" v2.1.0 que interactúa con prodigal para correr la identificación de ORFs en Jupyter.\n",
    "Se seleccionó el genoma de Bacillus subtilis NC_014976.1 de 4093599 nucleotidos.\n",
    "Se empleó ORF_FINDER para comparar los resultados obtenidos con pyrodigal.\n",
    "Se realizó la anotación con proka del genoma NC_014976.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL0KRKi-NvSE"
   },
   "source": [
    "Se preparó el entorno de trabajo para pyrodigal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (6.0)\n",
      "Requirement already satisfied: biopython in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.81)\n",
      "Requirement already satisfied: pyrodigal in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from biopython) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pyyaml biopython pyrodigal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy8LK2iTNvSG"
   },
   "source": [
    "Se cargan los paquetes a a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from typing import TextIO, Union\n",
    "import pandas as pd\n",
    "import pyrodigal\n",
    "import requests\n",
    "import yaml\n",
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haEutgQFNvSH"
   },
   "source": [
    "Se empleó el archivo config.yaml para evitar compartir información personal. \n",
    "El contenido del archivo yaml es el siguiente:\n",
    "email: \"nina_lcl@gmail.com\"\n",
    "id: \"NC_014976.1\"\n",
    "Y se colocó este archivo en la misma carpeta en donde se encuentra este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcevhzBLeeZb"
   },
   "source": [
    "Si utilizamos el archivo yaml podemos acceder a los valores de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.cwd() / \"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = config[\"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_id = config[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D0F4YfuNvSI"
   },
   "source": [
    "Se descargó el genoma completo en formato fasta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sequences(acc):\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=acc, rettype=\"fasta\")\n",
    "        return handle\n",
    "    except requests.HTTPError as err:\n",
    "        print(err.response.status_code)\n",
    "        print(err.response.text)\n",
    "        sleep(60)\n",
    "\n",
    "\n",
    "def get_fasta_sequences(acc_id):\n",
    "    def save_fasta(x):\n",
    "        handle = fetch_sequences(x)\n",
    "        output_prefix = str(Path.cwd() / x)\n",
    "        fasta_file = f\"{output_prefix}.fasta\"\n",
    "\n",
    "        with open(fasta_file, \"w\") as f:\n",
    "            f.write(handle.read())\n",
    "\n",
    "    if isinstance(acc_id, list):\n",
    "        [save_fasta(i) for i in acc_id]\n",
    "    else:\n",
    "        save_fasta(acc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fasta_sequences(refseq_id)\n",
    "#luego de este comando se descargó el archivo NC_014976.1.fasta en donde se encuentra el genoma completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bsub_prefix = str(Path.cwd() / refseq_id)\n",
    "input_file = SeqIO.read(f\"{Bsub_prefix}.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_finder = pyrodigal.OrfFinder()\n",
    "orf_finder.train(bytes(input_file.seq))\n",
    "\n",
    "with open(f\"{Bsub_prefix}.gff\", \"w\") as dst:\n",
    "    fasta_parser = SeqIO.parse(f\"{Bsub_prefix}.fasta\", \"fasta\")\n",
    "    for i, record in enumerate(fasta_parser):\n",
    "        genes = orf_finder.find_genes(bytes(record.seq))\n",
    "        genes.write_gff(dst, sequence_id=record.id, header=(i == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff3_header = [\n",
    "    \"seqid\",\n",
    "    \"source\",\n",
    "    \"type\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"score\",\n",
    "    \"strand\",\n",
    "    \"phase\",\n",
    "    \"attributes\",\n",
    "]\n",
    "#luego se genera el archivo NC_014976.1.gff en la carpeta donde se encuentra este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(f\"{Bsub_prefix}.gff\", names=gff3_header, comment=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC_014976.1</td>\n",
       "      <td>pyrodigal_v2.1.0</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3</td>\n",
       "      <td>1694</td>\n",
       "      <td>171.9</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=NC_014976.1_1;partial=10;start_type=Edge;rb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC_014976.1</td>\n",
       "      <td>pyrodigal_v2.1.0</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1798</td>\n",
       "      <td>2469</td>\n",
       "      <td>64.1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=NC_014976.1_2;partial=00;start_type=ATG;rbs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC_014976.1</td>\n",
       "      <td>pyrodigal_v2.1.0</td>\n",
       "      <td>CDS</td>\n",
       "      <td>2466</td>\n",
       "      <td>3173</td>\n",
       "      <td>80.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=NC_014976.1_3;partial=00;start_type=ATG;rbs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC_014976.1</td>\n",
       "      <td>pyrodigal_v2.1.0</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3160</td>\n",
       "      <td>4266</td>\n",
       "      <td>106.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=NC_014976.1_4;partial=00;start_type=GTG;rbs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC_014976.1</td>\n",
       "      <td>pyrodigal_v2.1.0</td>\n",
       "      <td>CDS</td>\n",
       "      <td>4263</td>\n",
       "      <td>5636</td>\n",
       "      <td>107.6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=NC_014976.1_5;partial=00;start_type=GTG;rbs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         seqid            source type  start   end  score strand  phase  \\\n",
       "0  NC_014976.1  pyrodigal_v2.1.0  CDS      3  1694  171.9      +      0   \n",
       "1  NC_014976.1  pyrodigal_v2.1.0  CDS   1798  2469   64.1      -      0   \n",
       "2  NC_014976.1  pyrodigal_v2.1.0  CDS   2466  3173   80.2      -      0   \n",
       "3  NC_014976.1  pyrodigal_v2.1.0  CDS   3160  4266  106.2      -      0   \n",
       "4  NC_014976.1  pyrodigal_v2.1.0  CDS   4263  5636  107.6      -      0   \n",
       "\n",
       "                                          attributes  \n",
       "0  ID=NC_014976.1_1;partial=10;start_type=Edge;rb...  \n",
       "1  ID=NC_014976.1_2;partial=00;start_type=ATG;rbs...  \n",
       "2  ID=NC_014976.1_3;partial=00;start_type=ATG;rbs...  \n",
       "3  ID=NC_014976.1_4;partial=00;start_type=GTG;rbs...  \n",
       "4  ID=NC_014976.1_5;partial=00;start_type=GTG;rbs...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se pueden visualizar las primeros CDS de todo el listado generado, también indica la versión del pyrodigal empleado (pyrodigal v2.1.0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4054, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identificaron 4054 CDS, los cuales también se pueden visualizar abriendo el archivo generado NC_014976.1.gff con el programa Notepad++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó la identificación de los ORFs para comparar los resultados obtenidos con pyrodigal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: credentials in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orf_finder.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import credentials\n",
    "import subprocess\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La siguiente estructura de datos te permite cambiar a otros códigos genéticos como por ejemplo de las mitocondrias que pueden usar el codón TGA para decodificar triptofano en vez de un codón de paro\n",
    "genetic_code= {\"AAA\":\"K\",\"AAC\":\"N\",\"AAG\":\"K\",\"AAT\":\"N\",\"ACA\":\"T\",\"ACC\":\"T\",\"ACG\":\"T\",\"ACT\":\"T\",\n",
    "                \"AGA\":\"R\",\"AGC\":\"S\",\"AGG\":\"R\",\"AGT\":\"S\",\"ATA\":\"I\",\"ATC\":\"I\",\"ATG\":\"M\",\"ATT\":\"I\",\n",
    "                \"CAA\":\"Q\",\"CAC\":\"H\",\"CAG\":\"Q\",\"CAT\":\"H\",\"CCA\":\"P\",\"CCC\":\"P\",\"CCG\":\"P\",\"CCT\":\"P\",\n",
    "                \"CGA\":\"R\",\"CGC\":\"R\",\"CGG\":\"R\",\"CGT\":\"R\",\"CTA\":\"L\",\"CTC\":\"L\",\"CTG\":\"L\",\"CTT\":\"L\",\n",
    "                \"GAA\":\"E\",\"GAC\":\"D\",\"GAG\":\"E\",\"GAT\":\"D\",\"GCA\":\"A\",\"GCC\":\"A\",\"GCG\":\"A\",\"GCT\":\"A\",\n",
    "                \"GGA\":\"G\",\"GGC\":\"G\",\"GGG\":\"G\",\"GGT\":\"G\",\"GTA\":\"V\",\"GTC\":\"V\",\"GTG\":\"V\",\"GTT\":\"V\",\n",
    "                \"TAA\":\"*\",\"TAC\":\"Y\",\"TAG\":\"*\",\"TAT\":\"Y\",\"TCA\":\"S\",\"TCC\":\"S\",\"TCG\":\"S\",\"TCT\":\"S\",\n",
    "                \"TGA\":\"*\",\"TGC\":\"C\",\"TGG\":\"W\",\"TGT\":\"C\",\"TTA\":\"L\",\"TTC\":\"F\",\"TTG\":\"L\",\"TTT\":\"F\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se colocó todos los nucleótidos en máyusculas. \n",
    "#Se reemplazó todas las bases por su reverso complementario, pero con minúsculas. Luego regresamos la secuencia a mayúsculas.\n",
    "#Finalmente se pone la secuencia en reverso\n",
    "def reverse_complement(sequence):\n",
    "  sequence= sequence.upper().replace(\"A\",\"t\").replace(\"C\",\"g\").replace(\"G\",\"c\").replace(\"T\",\"a\").upper()[::-1]\n",
    "  return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se avanzó de 3 en 3 nucleótidos y se agregpó cada triplete a una lista de python\n",
    "def get_codon_list(genome):\n",
    "    codon_list = []\n",
    "    for i in range(0, len(genome), 3):\n",
    "        codon = genome[i:i+3]\n",
    "        codon_list.append(codon)\n",
    "    return codon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_start(stop_pos_df,start_pos_df,stop_pos):\n",
    "    cur_stop_pos_index = stop_pos_df[stop_pos_df[\"stop_pos\"]==stop_pos].index[0]\n",
    "    if(cur_stop_pos_index==0):\n",
    "        prev_stop_pos = 0\n",
    "    elif(cur_stop_pos_index<len(stop_pos_df)):\n",
    "        prev_stop_pos_index = cur_stop_pos_index - 1\n",
    "        prev_stop_pos = stop_pos_df[\"stop_pos\"][prev_stop_pos_index]\n",
    "    cur_start_pos_index_list = start_pos_df[(start_pos_df[\"start_pos\"]>=prev_stop_pos) & (start_pos_df[\"start_pos\"]<stop_pos)][\"start_pos\"].index\n",
    "    if (len(cur_start_pos_index_list)==0):\n",
    "        cur_start_pos = np.nan\n",
    "    else:\n",
    "        cur_start_pos_index = cur_start_pos_index_list[0]\n",
    "        cur_start_pos = start_pos_df[\"start_pos\"][cur_start_pos_index]\n",
    "    return cur_start_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf_pos_list(genome,frame,orf_size):\n",
    "    genome_len = len(genome)\n",
    "    if frame<0:\n",
    "        genome = reverse_complement(genome)\n",
    "        tmp_frame = -1 * frame\n",
    "        genome = genome[tmp_frame-1:]\n",
    "    else:\n",
    "        genome = genome.upper()\n",
    "        genome = genome[frame-1:]\n",
    "    codon_list     = get_codon_list(genome)\n",
    "    stop_pos_list  = []\n",
    "    orf_pos_list   = []\n",
    "    codon_df       = pd.DataFrame(codon_list,columns=[\"codon\"])\n",
    "    codon_df       = pd.DataFrame(codon_list,columns=[\"codon\"])\n",
    "    start_pos_list = list(codon_df[codon_df[\"codon\"]==\"ATG\"].index)\n",
    "    stop_pos_list  = list(codon_df[(codon_df[\"codon\"]==\"TAA\") | (codon_df[\"codon\"]==\"TAG\") | (codon_df[\"codon\"]==\"TGA\")].index)\n",
    "    start_pos_df   = pd.DataFrame(start_pos_list,columns=[\"start_pos\"])\n",
    "    stop_pos_df    = pd.DataFrame(stop_pos_list,columns=[\"stop_pos\"])\n",
    "    pos_df         = stop_pos_df.copy()\n",
    "    pos_df[\"start_pos\"] = pos_df[\"stop_pos\"].apply(lambda x: get_nearest_start(stop_pos_df,start_pos_df,x))\n",
    "    pos_df = pos_df[pos_df[\"start_pos\"]>0]\n",
    "    pos_df[\"orf_len\"]   = pos_df[\"stop_pos\"] - pos_df[\"start_pos\"] + 1\n",
    "    pos_df = pos_df[pos_df[\"orf_len\"]>=orf_size]\n",
    "    if frame >0:\n",
    "        pos_df[\"orf_start_pos\"] = ((pos_df[\"start_pos\"] * 3) + 1) + (frame - 1)\n",
    "        pos_df[\"orf_stop_pos\"]  = ((pos_df[\"stop_pos\"]  + 1) * 3) + (frame - 1)\n",
    "    elif frame<0:\n",
    "        pos_df[\"orf_start_pos\"] = (genome_len + (1+frame) ) - ( pos_df[\"start_pos\"]     * 3)\n",
    "        pos_df[\"orf_stop_pos\"]  = (genome_len + (1+frame) ) - ((pos_df[\"stop_pos\"] + 1) * 3)\n",
    "    orf_pos_list = pos_df[[\"orf_start_pos\",\"orf_stop_pos\"]].astype(int).values.tolist()\n",
    "    return orf_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf_sequence(orf_df,genome,orf_id):\n",
    "    strand    = list(orf_df[orf_df[\"id\"]==orf_id][\"strand\"])[0]\n",
    "    start_pos = int(orf_df[orf_df[\"id\"]==orf_id][\"start\"])\n",
    "    stop_pos  = int(orf_df[orf_df[\"id\"]==orf_id][\"stop\"])    \n",
    "    if(strand==\"-\"):\n",
    "        orf_sequence = genome[start_pos:stop_pos]\n",
    "        orf_sequence = reverse_complement(orf_sequence)\n",
    "    else:\n",
    "        orf_sequence = genome[start_pos-1:stop_pos]\n",
    "    return orf_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Se tomó la secuencia del ORF, que obtuvimos con `get_orf_sequence()`\n",
    "#- Se utilizó `get_codon_list()` para convertir en una lista de codones\n",
    "#- Se mapeó cada cada codón con el diccionario del código genético para determinar que aminoácido le corresponde a cada codón###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_orf(orf_sequence):\n",
    "    amino_acid_str = \"\"\n",
    "    codon_list = get_codon_list(orf_sequence)\n",
    "    for codon in codon_list:\n",
    "        amino_acid = genetic_code[codon]\n",
    "        amino_acid_str += amino_acid\n",
    "    return amino_acid_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. DESCARGA DE UN GENOMA\n",
    "2.1. Se descargó un genoma usando la biblioteca de NCBI - Entrez (efech)\n",
    "\n",
    "Se eliminó el encabezado de la secuencia y se dejó el genoma en una sola línea de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_name = \"NC_014976.1\"\n",
    "#genome_name = \"BSUB\"\n",
    "genome = Entrez.efetch(db=\"nucleotide\", id=genome_name, rettype=\"fasta\", retmode=\"text\").read()\n",
    "genome = re.sub(r\"\\>.*\\n\", \"\", genome).replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.2. Obtención de las posiciones de los ORFs mayores a \"100\" amino ácidos en cada uno de los seis marcos de lectura usando las funciones ya definidas en el paso 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_one_pos_list    = get_orf_pos_list(genome, 1,100)\n",
    "plus_two_pos_list    = get_orf_pos_list(genome, 2,100)\n",
    "plus_three_pos_list  = get_orf_pos_list(genome, 3,100)\n",
    "minus_one_pos_list   = get_orf_pos_list(genome,-1,100)\n",
    "minus_two_pos_list   = get_orf_pos_list(genome,-2,100)\n",
    "minus_three_pos_list = get_orf_pos_list(genome,-3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.3. Construcción de dos dataframes, indicando los ORFs localizados en la cadena positiva del genoma y los ORFs localizados en la cadena negativa del genoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_orf_pos_list  = plus_one_pos_list  + plus_two_pos_list  + plus_three_pos_list\n",
    "minus_orf_pos_list = minus_one_pos_list + minus_two_pos_list + minus_three_pos_list\n",
    "plus_orf_df = pd.DataFrame(plus_orf_pos_list,columns=[\"start\",\"stop\"])\n",
    "minus_orf_df = pd.DataFrame(minus_orf_pos_list,columns=[\"stop\",\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.4. Se agregó la información de la cadena a cada uno de los dataframes\n",
    "\n",
    "#Con la última línea se concatenaron los ORFs luego de etiquetarlos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_orf_df[\"strand\"]  = \"+\"\n",
    "minus_orf_df[\"strand\"] = \"-\"\n",
    "plus_orf_df = plus_orf_df[[\"start\",\"stop\",\"strand\"]]\n",
    "minus_orf_df = minus_orf_df[[\"start\",\"stop\",\"strand\"]]\n",
    "orf_df = pd.concat([plus_orf_df,minus_orf_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1. Al concatenar los dataframes, los ORFs no quedan ordenados de forma lógica, por lo que debemos ordenarlos con base en su coordenada de inicio\n",
    "\n",
    "#Se les agregó una etiqueta a los ORF y se indicó su número de aparición en el genoma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df = orf_df.sort_values(by=[\"start\"],ignore_index=True)\n",
    "orf_df[\"genome\"] = genome_name\n",
    "orf_df[\"id\"] = np.arange(len(orf_df)).astype(str)\n",
    "orf_df[\"id\"] = orf_df[\"genome\"]+\".\"+orf_df[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.5. Obtención de la secuencia codificante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df[\"orf_sequence\"] = orf_df[\"id\"].apply(lambda x: get_orf_sequence(orf_df,genome,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.6. Se empleó translate_orf() para agregar la traducción de la secuencia  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df[\"orf_translation\"] = orf_df[\"orf_sequence\"].apply(lambda x: translate_orf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcción de un archivo .gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df[\"info\"] = \"Id=\"+orf_df[\"id\"]+\";translation=\"+orf_df[\"orf_translation\"]+\";product=hypothetical protein\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7. Se agregó un par de columnas que indican que tipo de información y de que fuente se está teniendo dicha información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df[\"score\"]  = \".\"\n",
    "orf_df[\"phase\"]  = \".\"\n",
    "orf_df[\"type\"]   = \"CDS\"\n",
    "orf_df[\"source\"] = \"python_orfinder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empleó la función `.to_csv()` de pandas para almacenar la información del dataframe a un archivo tabular, \n",
    "en este punto ya tenemos la información necesaria para guardar nuestras predicciones en un archivo `.gff`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_df[[\"genome\",\"source\",\"type\",\"start\",\"stop\",\"score\",\"strand\",\"phase\",\"info\"]].to_csv(genome_name+\".gff\",sep=\"\\t\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Se guardaron las traducciones de ORF en un archivo NC_014976.1.faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(genome_name+\".faa\",\"w\") as file_name:\n",
    "    fasta_str = \"\"\n",
    "    for orf_id,orf_translation in list(orf_df[[\"id\",\"orf_translation\"]].values):\n",
    "        fasta_str += \">\" + orf_id + \"\\n\" + orf_translation +\"\\n\"\n",
    "    file_name.write(fasta_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type NC_014976.1.gff\n",
    "#este archivo también se puede abrir con el programa Notepad++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! type NC_014976.1.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARTE 3\n",
    "\n",
    "Se realizó la anotación del genoma NC_014976.1 empleando en servidor prokka para procariotas ubicado en https://usegalaxy.org/  y el archivo tipo fasta descargado inicialmente donde figura el genoma completo. Primero se carga el archivo utilizando la \n",
    "flecha de la izquierda \"cargar datos\" , haciendo clic en la opción \"elegir archivos locales\", seleccionando el tipo de archivo \"fasta\". Luego buscar prokka en la ventana de la izquierda y seleccionar el archivo cargado y la opción Bacteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eggnog mapper  \n",
    "También se evaluó el genoma en el servidor Eggnog mapper\n",
    "\n",
    "http://eggnog-mapper.embl.de/submit_job\n",
    "http://eggnog-mapper.embl.de/MM_vpez1efu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTADOS\n",
    "\n",
    "\n",
    "\n",
    "#PYRODIGAL:  4054 CDS pyrodigal v2.1.0\n",
    "#ORF_FINDER: 4660 CDS python orf_finder\n",
    "#EGGNOTE 511 CDS#\n",
    "#Anotación PROKKA: De las 4157 secuencias detectadas (archivo Galaxy23-[Prokka_on_data_14__tsv].tabular)\n",
    "            #4042 CDS prodigal:002006, \n",
    "            #83 AtRNA y 1 mtRNA con Aragorn, \n",
    "            #31 rRNA con barrnap:0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REFERENCIAS:\n",
    "\n",
    "Deng, Y., Zhu, Y., Wang, P., Zhu, L., Zheng, J., Li, R., ... & Sun, M. (2011). Complete genome sequence of Bacillus subtilis BSn5, an endophytic bacterium of Amorphophallus konjac with antimicrobial activity for the plant pathogen Erwinia carotovora subsp. carotovora.\n",
    "\n",
    "Hyatt, D., Chen, GL., LoCascio, P.F. et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics 11, 119 (2010). doi:10.1186/1471-2105-11-119.\n",
    "\n",
    "Larralde, M., (2022). Pyrodigal: Python bindings and interface to Prodigal, an efficient method for gene prediction in prokaryotes. Journal of Open Source Software, 7(72), 4296. doi:10.21105/joss.04296.\n",
    "\n",
    "Seemann, T. (2014). Prokka: rapid prokaryotic genome annotation. Bioinformatics, 30(14), 2068-2069. doi.org/10.1093/bioinformatics/btu153"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
